{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a89ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html5lib\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f5b2ec",
   "metadata": {},
   "source": [
    "After scrapping the webstie basketball-reference.com, now we need to put the information countained in each html file in a big data frame that is going to be used later for our machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda2096",
   "metadata": {},
   "source": [
    "# Retrieving the data from our directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fd89d",
   "metadata": {},
   "source": [
    "### 1) Defining some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ca678",
   "metadata": {},
   "source": [
    "First we create a list that countains the paths to all the boxscores files in our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba7d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_DIR = \"data2/Scores\"\n",
    "box_scores = os.listdir(SCORE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4f66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_scores = [os.path.join(SCORE_DIR, f) for f in box_scores if f.endswith(\".html\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5a4a9",
   "metadata": {},
   "source": [
    "We then need to define multiple functions:\n",
    " - One function __parse_html__ that will return a soup object to us. \n",
    " - That soup object will then be used by multiple functions:\n",
    "     - __read_line_score__ : This function extracts the name of the teams and the number of points scored by each one\n",
    "     - __read_stats__ : This function extracts the table that countains the players' individual stats as well as the teams' stats\n",
    "     - __read_season_info__: This function returns the year when the game was played\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce028a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(box_score):\n",
    "    \"\"\"\n",
    "    Parse an HTML file containing sports game data.\n",
    "\n",
    "    Parameters:\n",
    "    - box_score (str): The path to the HTML file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "    - soup (BeautifulSoup object): A BeautifulSoup object representing the parsed HTML.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Try to open and read the HTML file\n",
    "        with open(box_score, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        # Create a BeautifulSoup object to parse the HTML\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        # Remove elements with specific CSS classes from the parsed HTML\n",
    "        [s.decompose() for s in soup.select(\"tr.over_header\")]  # Remove rows with \"over_header\" class\n",
    "        [s.decompose() for s in soup.select(\"tr.thead\")]       # Remove rows with \"thead\" class\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, typically for file reading errors\n",
    "        print(f\"Error processing {box_score}: {str(e)}\")\n",
    "\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f06ebbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_score(soup):\n",
    "    \"\"\"\n",
    "    Extract and format line score data (team names and total score) from parsed HTML.\n",
    "\n",
    "    Parameters:\n",
    "    - soup (BeautifulSoup object): The BeautifulSoup object representing the parsed HTML.\n",
    "\n",
    "    Returns:\n",
    "    - line_score (DataFrame): A Pandas DataFrame containing team names and total score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the line score table from the parsed HTML using its \"id\" attribute\n",
    "    line_score = pd.read_html(str(soup), attrs={\"id\": \"line_score\"})[0]\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    cols = list(line_score.columns)\n",
    "    cols[0] = \"Team\"        # Rename the first column to \"Team\"\n",
    "    cols[-1] = \"Total\"      # Rename the last column to \"Total\"\n",
    "    line_score.columns = cols\n",
    "\n",
    "    # Keep only the \"Team\" and \"Total\" columns because we are interested in team names and total score\n",
    "    line_score = line_score[[\"Team\", \"Total\"]]\n",
    "\n",
    "    return line_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6367d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats(soup, team, stat):\n",
    "    \"\"\"\n",
    "    Extract and convert statistical data (basic or advanced) for a specific team from parsed HTML.\n",
    "\n",
    "    Parameters:\n",
    "    - soup (BeautifulSoup object): The BeautifulSoup object representing the parsed HTML.\n",
    "    - team (str): The name of the team for which statistics are being extracted.\n",
    "    - stat (str): The type of statistics to extract (e.g., \"basic\" or \"advanced\").\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): A Pandas DataFrame containing the extracted statistical data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the statistical table for the specified team and type (basic or advanced)\n",
    "    # The \"id\" attribute is constructed using team and stat variables\n",
    "    df = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-{stat}\"}, index_col=0)[0]\n",
    "\n",
    "    # Convert all data in the DataFrame to numeric values, handling non-numeric values by coercing them to NaN\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e79a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup):\n",
    "    \"\"\"\n",
    "    Extract and return the season information from the parsed HTML.\n",
    "\n",
    "    Parameters:\n",
    "    - soup (BeautifulSoup object): The BeautifulSoup object representing the parsed HTML.\n",
    "\n",
    "    Returns:\n",
    "    - season (str): The year when the game was played.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the navigation container with the id \"bottom_nav_container\"\n",
    "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
    "\n",
    "    # Extract the href attributes from all the anchor (a) elements within the navigation container\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all(\"a\")]\n",
    "\n",
    "    # Get the second element from the hrefs list, split it using underscores, and extract the first part\n",
    "    season = os.path.basename(hrefs[1]).split(\"_\")[0]\n",
    "\n",
    "    return season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2654ce8",
   "metadata": {},
   "source": [
    "### 2) Applying the functions and creating the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "base_cols = None  # A list of columns for the summary data\n",
    "games = []  # A list to store processed game data\n",
    "\n",
    "# Iterate through each box score in the collection\n",
    "for box_score in box_scores:\n",
    "\n",
    "    # Check if the box score file is empty, and if so, skip it\n",
    "    if os.path.getsize(box_score) == 0:\n",
    "        continue  # Skip empty files\n",
    "\n",
    "    # Parse the HTML content of the box score\n",
    "    soup = parse_html(box_score)\n",
    "\n",
    "    # Read the line score data from the parsed HTML\n",
    "    line_score = read_line_score(soup)\n",
    "\n",
    "    # Extract the list of teams from the line score\n",
    "    teams = list(line_score[\"Team\"])\n",
    "\n",
    "    # Initialize a list to store summaries for each team in the game\n",
    "    summaries = []\n",
    "\n",
    "    # Iterate through each team in the game\n",
    "    for team in teams:\n",
    "        try:\n",
    "            # Read basic and advanced statistics for the team\n",
    "            basic = read_stats(soup, team, \"basic\")\n",
    "            advanced = read_stats(soup, team, \"advanced\")\n",
    "\n",
    "            # Combine total statistics and set lowercase index labels\n",
    "            totals = pd.concat([basic.iloc[-1, :], advanced.iloc[-1, :]])\n",
    "            totals.index = totals.index.str.lower()\n",
    "\n",
    "            # Calculate maximum statistics and set lowercase index labels\n",
    "            maxes = pd.concat([basic.iloc[:-1, :].max(), advanced.iloc[:-1, :].max()])\n",
    "            maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "            # Combine totals and maximums to create a summary\n",
    "            summary = pd.concat([totals, maxes])\n",
    "\n",
    "            # If base_cols is None, initialize it with unique columns and exclude those containing \"bpm\"\n",
    "            if base_cols is None:\n",
    "                base_cols = list(summary.index.drop_duplicates(keep='first'))\n",
    "                base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "\n",
    "            # Select only the columns present in base_cols for the summary\n",
    "            summary = summary[base_cols]\n",
    "\n",
    "            # Append the summary to the list of summaries for this game\n",
    "            summaries.append(summary)\n",
    "\n",
    "        except ValueError:\n",
    "            # Handle the case where a table is missing (e.g., data not available)\n",
    "            print(f\"Missing table at {len(games)}\")\n",
    "            continue\n",
    "\n",
    "    # Combine all team summaries horizontally and transpose the result\n",
    "    summary = pd.concat(summaries, axis=1).T\n",
    "\n",
    "    # Combine the summary data with the line score data horizontally\n",
    "    game = pd.concat([summary, line_score], axis=1)\n",
    "\n",
    "    # Add a \"home\" column with values [0, 1] to indicate home and away teams\n",
    "    game[\"home\"] = [0, 1]\n",
    "\n",
    "    # Reverse the order of rows and reset column names with \"_opp\" suffix\n",
    "    game_opp = game.iloc[::-1].reset_index()\n",
    "    game_opp.columns += '_opp'\n",
    "\n",
    "    # Combine the original game data and the \"opposite\" game data horizontally\n",
    "    full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "    # Read and assign season information from the parsed HTML\n",
    "    full_game[\"season\"] = read_season_info(soup)\n",
    "\n",
    "    # Extract the date from the file name and convert it to a datetime object\n",
    "    full_game[\"date\"] = os.path.basename(box_score)[:8]\n",
    "    full_game[\"date\"] = pd.to_datetime(full_game['date'], format=\"%Y%m%d\")\n",
    "\n",
    "    # Add a \"won\" column indicating whether the team won the game based on total points\n",
    "    full_game[\"won\"] = full_game[\"Total\"] > full_game[\"Total_opp\"]\n",
    "\n",
    "    # Append the processed game data to the list of games\n",
    "    games.append(full_game)\n",
    "\n",
    "    # Print progress information for every 100 processed games\n",
    "    if len(games) % 100 == 0:\n",
    "        print(f\"{len(games)}/{len(box_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62f4df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.concat(games, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0671eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"nba_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298ff20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
